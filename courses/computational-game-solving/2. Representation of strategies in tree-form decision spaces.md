[Link](https://www.cs.cmu.edu/~sandholm/cs15-888F21/L02_sequence_form.pdf)
***

##### 0 - Introduction

- This lecture demonstrates how strategies are represented for the case of _tree-form_ decision making. <br/><br/>
- Two critical properties of a game representation: <br/><br/>
	- The set of strategies is a convex and compact set. <br/><br/>
	- Each player's utility function is multilinear. <br/>


These two properties guarantee optimization methods can be used.<br/><br/>

##### 1 - Tree-Form Decision Making

- <span style="color:cyan"><i>Tree-form sequential decision process</i></span> (TFSDP) - Problem where the agent interacts with the environment in two ways:
	- <span style="color:cyan"><i>Decision points</i></span> - agent must select an action from a set of legal actions.
	- <span style="color:cyan"><i>Observation points</i></span> - agent observes a signal from the environment.
	
	Decision and observation points are structured sequentially into a tree. <br/>
	_Note:_ It is assumed the agent isn't forgetful, so the tree never cycles back to a previously visited point.
<br/>

- TFSDPs provide a general formalism for extensive-form games with perfect recall.
   (ex. poker, bridge, MDP) 
<br/>

- Summary of notation in TFSDPs: <br/>
	- $\mathcal{J}$ - set of decision points. <br/>
	- $A_j$ - set of legal actions. <br/>
	- $\mathcal{K}$ - set of observation points. <br/>
	- $S_k$ - set of possible signals at observation point $k \in \mathcal{K}$ <br/>
	- $\sum$ - set of sequences defined as $\sum := {(j,a): j \in \mathcal{J}, a \in A_j}$ <br/>
	 - $p_j$ - parent sequence of decision point $j \in \mathcal{J}$ , defined as the last sequence on the path from the root of the TFSDP to decision point $j$.
	   (null set if the agent doesn't act before $j$)
<br/>

- <span style="color:cyan"><i>Sequence</i></span> ($(j,a)$ or $ja$) - decision-action pair.
- <span style="color:cyan"><i>Parent sequence</i></span> ($p_j$) - the last decision point encountered before the decision point $j$.
<br/>

- Differences between TFSDPs and extensive-form games:
	- TFSDPs define the decision problem for a single agent.
	- Extensive-form games encode the dynamics of all agents involved. 
	- EFG, decision nodes belong to players and observation nodes belong to a fictitious player, nature, who chooses a stochastic action.
<br/>
- Similarities between TFSDPs and extensive-form games:
	- decision points = information sets
	- sequences = (information set, action) pairs.
<br/>

##### 2 - Strategies in Tree-Form Decision Making

- A strategy for an agent in a TFSDP specifies a distribution over the set of actions $A_j$ at each decision point $j \in \mathcal{J}$ .
<br/>

###### 2.1 - Behavioral Strategies

- <span style="color:cyan"><i>Behavioral strategy</i></span> - defines the probability for selecting an action given a decision point, for every sequence. Noted as a vector indexed over sequences, $\mathbf{x} \in \mathbb{R}_{\geq0}^{|\sum|}$

> Major drawback of this representation: in order to determine the probability of reaching a given terminal state, we must compute the product of all actions on the path.<br/>
> This causes some expressions which depend on this probability to be non-convex.
> (ex. expected utility)
<br/>
###### 2.2 - Sequence-Form Strategies

- <span style="color:cyan"><i>Sequence-form representation</i></span> - defines the product of the probabilities of all actions at all decision points on the path from the root to the action $a$ at decision point $j$. <br/> Noted as a vector over sequences, $\mathbf{x} \in \mathbb{R}_{\geq0}^{|\sum|}$ <br/>

_Note:_ Is this the probability of taking a given action in a given state when at the root? <br/>

- Probability-mass-conservation constraints:
	- For $p_j \neq \varnothing$ (non-root decision points),   $\sum_{a \in A_j} \mathbf{x}[ja] = \mathbf{x}[p_j]$
	- For $p_j = \varnothing$ (root decision points), $\sum_{a \in A_j}\mathbf{x}[ja] = 1$ 

> Because of the probability-mass-conservation constraint, the set of valid sequence-form strategies (denoted $Q$) is convex. <br/>
> $$Q := \Biggl\{\mathbf{x} \in \mathbb{R}_{\geq0}^{|\sum|} \: : \: \sum_{a \in A_j} \mathbf{x}[ja] = \begin{cases} 1, & \text{if}\ p_j=\varnothing \\ \mathbf{x}[p_j], & \text{otherwise} \end{cases} \: \Biggr\}$$
<br/><br/>


###### 2.3 - Deterministic and Randomized Sequence-Form Strategies

- <span style="color:cyan"><i>Deterministic strategies</i></span> - strategies that always select the same action at each decision point. Deterministic strategies are a subset of all possible strategies.
<br/>

- In sequence-form representation, deterministic strategies are the subset of $Q$ whose elements are all either $0$ or $1$.

   $\prod := Q \cap \{0, 1\}^{|\sum|}$ 
<br/>

- <span style="color:cyan"><i>Reduced normal-form strategies</i></span> - the set of deterministic sequence-form strategies, in game theory.
<br/>

- <span style="color:red"><b>Theorem:</b></span> the set of deterministic sequence-form strategies generates the polytope of sequence-form strategies, that is, $Q = co\prod$ 

###### 2.4 Bottom-up decomposition of the polytope of sequence-form strategies

- The sequence-form representation lends itself nicely to several common optimization procedures.
  <br/>

- One such procedure is _bottom-up_ decomposition - work from the leaf nodes upward to the root, constructing the sequence-form representation at each node node.
  <br/>

- This process is done using two operations which conserve convexity: <br/><br/>
	- _Cartesian product_ - the cartesian product of two sets yields a new set of all possible combinations of the input sets. $A \times B = \{(a,b) : a \in A, b \in B\}$. <br/> <br/>
	- _Convex hull_ - the convex hull of a set yields the smallest set that contains all points of the input set. This is akin to taking a linear weighted average of the points in a set. <br/>
	   Ex. $X=\{x_1, x_2\}, \: \textrm{co}(X)=\{\alpha x_1 + (1-\alpha)x_2 \: | \: 0 \leq \alpha \leq 1\}$. This is the set of points between $x_1$ and $x_2$. The convex hull of a set with three points forms a triangle in 2D.
<br/>

- Bottom-up construction rules: <br/> <br/>
	- _Leaf nodes_ - $Q_{\text{leaf}}=\Delta_n$ where $\Delta$ is a probability simplex and $n$ is the number of actions. <br/> <br/>
	- _Decision points_ - convex hull of the child node strategies. The set of strategies rooted at a decision node is the linear combination of child strategies weighted by the probability of taking the actions that lead to each child. <br/><br/>
	- _Observation points_ - cartesian product of the child node strategies. The set of strategies rooted at an observation node is the combination of the independent strategies at its child nodes.

